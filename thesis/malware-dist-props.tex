\section{Adapting ZOP to Detect Malware}
\label{adapt_zop}

In Chapter~\ref{zop}, ZOP profiled devices using a small EM probe very close to the device being profiled. This chapter builds on ZOP and addresses two new requirements: (1) in addition to predicting the most likely control flow path through a program, predict whether ``unknown'' code (e.g. malware) executed, and (2) do this prediction from a distance of 3 meters. Chapter~\ref{zop} measured the average accuracy of counts of all the dynamic occurrences of acyclic intraprocedural paths in a program across a set of inputs. That metric is only useful for path profiling, but for other applications such as malware detection, we will need a new metric which can be used to measure whole program path prediction accuracy. When determining whole program path prediction accuracy, we have two paths to compare. The first path is the sequence of basic blocks that the program actually executed for a given input (call this sequence $S$), and the second is the sequence of basic blocks that ZOP predicts for that same execution (call this sequence $T$). One efficient method of comparing two sequences of symbols is the string edit distance which we will call $d(S,T)$. The string edit distance is a single number which is the total edits necessary to transform sequence $S$ into sequence $T$. This transformation consists of a sequence of edits where each edit consists of deleting a single symbol from $S$ or adding a single symbol to $S$. The edits are applied iteratively to sequence $S$ until the sequence $T$ is produced, and the edit distance is defined as the minimum number of edits necessary to transform $S$ into $T$. In this formulation, each unique basic block is a symbol. In this chapter we will use the unique markers as symbols for convenience and because we only have the timing of the markers (not the basic blocks) in the observed waveforms. This ``marker edit distance'' can be converted to a fraction by calculating $\frac{d(S,T)}{|S|}$. This fraction indicates the percentage of the program whose path was mispredicted, and the whole program path prediction accuracy will be calculated as $1 - \frac{d(S,T)}{|S|}$. This metric is useful for summarizing whole program path prediction accuracy for a given execution and for isolating the time periods where the predicted path is incorrect in a particular execution. Both of these are important tools for understanding path prediction accuracy.

To understand how ZOP can be adapted to detect malware, consider how ZOP would behave when it attempts to predict the control flow path through a program when unknown code (malware) is present. For our purposes, we will focus on unknown code, i.e. any code which we haven't observed as part of the monitored program during training. This unknown code could be part of any type of malware that results in the execution of code not present in monitored program, such as a buffer overflow attack or a clandestine malicious modification to the program. When we use ZOP to predict the path through a program where unknown code is present, ZOP will accurately predict the path through the program for the portions of the execution where the known code is active. For the portions of the program where unknown code is active, ZOP attempts to match the EM emanations waveforms generated by the unknown code to the training waveforms for the known program. If the unknown code is active for a long enough period of time, the execution of this unknown code is virtually guaranteed to generate EM emanations waveforms which match the training waveforms quantifiably worse than any valid execution of known code in the monitored program. In other words, when malware is present the received signal will not match any training examples resulting in low confidence in the path prediction results since the malware will not correspond to any valid program path. Therefore high accuracy malware detection requires ZOP to not only predict the execution path correctly, but also requires that the training and execution waveforms match (e.g. correlate) with high confidence when known code executes.

\section{ZOP Whole Program Path Prediction Accuracy on NIOS and PIC32 Processors}
\label{malware-dist-static}
In this section, we will use ZOP to predict the whole program path on the NIOS processor (used in Chapter~\ref{zop}) and also on a simpler PIC32 processor. The NIOS processor uses an external memory and has on-chip data and instruction caches which introduce microarchitectural event differences (such as cache hit/misses) among dynamic instances of a given static path. The Microchip PIC32MX795F512L is a 32 bit, 80 MHz processor with similar architecture to NIOS, with the main difference being that it uses neither external memory nor on-chip instruction and data caches. This difference is important, as the lack of a cache and external memory greatly minimizes the effect of processor microarchitectural event differences when executing a given static path. On the PIC32 processor, repeated executions of a given static path will execute in nearly the same number of clock cycles and the EM emanations waveform for each dynamic instance of a single static path are highly correlated to one another. To remove any effects caused by differences in processor/memory clock rates between the processors, for all the measurements in this chapter we set the NIOS processor and memory clock rate to 83.333 MHz (this is the closest FPGA PLL frequency available near the PIC32's 80 MHz clock rate). Any difference in ZOP's performance between these two processors is likely due to microarchitectural event variations present only in the NIOS processor, since this is the key difference between the two processors. Other signal effects (noise, signal propagation, etc.) will be minimal and equivalent between the two processors because they will be measured under the same conditions. 
%Therefore, differences in performance between measurements on the PIC32 and NIOS processors are likely ca.

\begin{table}[hbt]
\includegraphics[width=5in]{pic32_performance}
\caption{A comparison of ZOP's whole program path prediction performance on the PIC32 and NIOS processors for the replace benchmark measured using the marker edit distance ratio.}
\label{pic32_performance}
\end{table}

To evaluate the difference in ZOP's whole program path prediction performance on the NIOS and PIC32 processors, the replace benchmark was run using the same sets of training and evaluation inputs and same measurement setup (i.e. a small tuned LC probe very close to the monitored processor) as described in Chapter~\ref{zop}. Table~\ref{pic32_performance} shows a performance comparison using the marker edit distance ratio metric described in Section~\ref{adapt_zop}. The whole program path was predicted exactly or almost completely correctly for vast majority of the inputs (those with marker edit distance ratio less than 0.01). For 6 evaluation inputs on the PIC32 and for 18 evaluation inputs on NIOS, the marker edit distance was very large ($>$ 0.25). The performance on these inputs was investigated, and it was found that for almost all such inputs the execution was very short ($>$ 10 markers long), so that missing only a few markers resulted in a large marker edit distance ratio. For 3 of the executions with a large marker edit distance ratio the executions were, however, sufficiently long that we can conclusively say that ZOP completely failed and lost track of the actual execution path. After investigation, it was determined that these inputs all got lost in the function shown in Figure~\ref{replace_omatch}.

\begin{figure}[h]
  \centering
\lstset{language=C++,basicstyle=\ttfamily\scriptsize,numbers=left}\lstset{escapeinside={/*@}{@*/}}
\begin{lstlisting}[frame=none,xleftmargin=30pt]
int omatch(char *lin, int *i, char *pat, int j) {
  char advance = -1;
  bool result;
  mark(A);
  if (lin[*i] == ENDSTR) result = false;
  else if (!in_pat_set(pat[j])) {
    return false;
  } else {
    switch (pat[j]) {
    case LITCHAR:
      if (lin[*i] == pat[j + 1]) advance = 1;
      break;
    case BOL:
      if (*i == 0) advance = 0;
      break;
    case ANY:
      if (lin[*i] != NEWLINE) advance = 1;
      break;
    case EOL:
      if (lin[*i] == NEWLINE) advance = 0;
      break;
    case CCL:
      if (locate(lin[*i], pat, j + 1)) advance = 1;
      break;
    case NCCL:
      if ((lin[*i] != NEWLINE) && (!locate(lin[*i], pat, j + 1))) {
        advance = 1;
      }
      break;
    default:
      Caseerror(pat[j]);
    }
  }
  if ((advance >= 0)) {
    *i = *i + advance;
    result = true;
  } else {
    result = false;
  }
  mark(B);
  return result;
}
\end{lstlisting}
\caption{A function which had poor static path coverage in the replace benchmark.}\label{replace_omatch}
\end{figure}

The function in Figure~\ref{replace_omatch} only has two markers, one at the start and one at the end of the function. Without the basic block sequence information for each dynamic path, it is impossible to determine the path coverage of the training set. However, the number of possible paths through this function is large, and given the criteria used to select the training inputs in Chapter~\ref{zop}, it is expected that many of the marker-to-marker paths through this function are not present in the training set. Based on this comparison, we propose that this training set has mostly adequate coverage of the marker-to-marker static paths with a few such exceptions. Furthermore, it was observed that repeated executions of replace with the same inputs and initial cache state showed very little variability in the EM emanations waveform (see Section~\ref{malware-dist-snr} for more information), so the effects of signal propagation, noise, and other distortions was negligible for this measurement setup. We conclude therefore that the decreased performance on NIOS (compared to PIC32) is due to microarchitectural variation (e.g. variation introduced by the external DRAM and on-chip caches), since all other effects should be the same between the NIOS and PIC32 measurements.




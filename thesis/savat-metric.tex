Assume an attacker has access to a program's source code or executable and can observe EM emanations from the victim's system while this program is running. The attacker attempts to extract sensitive information by recording EM emanations from the victim system while the program is running. The attacker then uses these recorded signals to infer which instructions are executed, and then infers sensitive data from knowledge of the executed instructions. The difficulty with which the attacker can obtain the sensitive information depends on both (1) program activity: the information-dependent difference created at the instruction level, and (2) the side channel signal's dependence on these instruction-level differences. 

The SAVAT metric quantifies this second property for a system. This allows (1) programmers to change their code to avoid creating high-\SAVAT instruction-level differences that depend on secret information, and (2) computer architects and microarchitects to focus their side channel mitigation efforts on high-\SAVAT instructions. Most side channel mitigation techniques are expensive, especially if applied very broadly. For example, circuit-level techniques that mask input-dependent variations in overall activity do so by performing more activity overall: when actual inputs require little activity, additional unnecessary activity is performed to match what happens for high-activity values. This minimizes variations in power consumption, EM activity, etc. The costs of these techniques are high: large increases in chip area (for dummy-activity circuitry), execution times that always match the worst case inputs, and power consumption that always equals the peak power consumption.

To develop a targeted approach to identifying information leakage, we will create a model that assumes that information leakage through side channels occurs when the instructions executed depend on sensitive information, and that this instruction-level difference creates a side channel signal that is available to the attacker. A program with input-dependent behavior will generate data-dependent activity in the processor and possibly also in the off-chip memory and other system components. This data-dependent activity will create signals in various side channels. Data-dependent activity in the system cannot be avoided: even if the program's control flow does not depend on the value of the input, and if the circuitry of the processor is designed such that every operand value results in the exact same overall number of bit-flips in transistors and wires, there will be at least some transistors or wires whose switching activity is input-dependent. This difference in transistor/wire activity creates a difference in various physical side channel signals, such as EM emanations, power consumption, etc. Process variations, physical location of the circuit, etc. allow side channel signals to be created even if the circuitry is designed to minimize the operand-dependent variations in overall activity -- these techniques can dramatically reduce the magnitude of data-dependent signal variation but cannot completely eliminate them. But this does not mean that these and other techniques are ineffective -- they force attackers to use more expensive, bulkier, and less widely available snooping devices, to run more risk of discovery (e.g. if they get closer to collect the weak EM emanations), and/or to need more data points and collect signals longer for the same amount of extracted information.

Many attacks rely on instruction-level differences in execution caused by data-dependence on sensitive information. For example, modular exponentiation in RSA is typically implemented in a way that results in testing the bits of the secret exponents one at time, and multiplying two large numbers (e.g. 2048 bits) whenever such a bit is 1. This entire multiplication can thus be viewed as the difference in execution caused by sensitive information (a bit of the exponent). This example also shows that, although the signal leaked by a single-instruction difference can be small, a practical attack may accumulate many of these single-instruction differences -- an entire large-numbers multiplication in this example. 

As another example, suppose an attacker can isolate (in the recorded EM signal) the time offset of a single branch instruction in the program, and suppose that this branch instruction is taken or not taken depending on a sensitive data bit. The attacker observes the side channel signal for a time period immediately following the branch. The executed instructions and/or data following the branch may be different depending on whether the branch is taken, and so the recorded signal may be different when the branch is taken or not taken. Using this signal difference, an attacker may be able to determine whether the branch is taken (and therefore determine the sensitive bit) using a procedure such as DPA. If we call the voltage signal corresponding to a taken branch $s_a(t)$ and the signal for the branch not taken $s_b(t)$, then we can estimate the total side-channel energy available to the attacker to determine whether the branch was taken as
\begin{equation}
  \textrm{SAVAT}(s_a,s_b) \equiv \int_{0}^{T_s} (s_a(t) - s_b(t))^2 dt/R
\end{equation}
where the $s_a(t)$ and $s_b(t)$ voltages are measured across a resistance $R$, and $t = (0,T_s)$ is the time interval after the tested branch where $s_a(t)$ and $s_b(t)$ differ depending on whether the branch is taken. Many other data dependent dependent activities cause such differences. For example, a signal difference may be created when a cache hit or miss occurs depending on sensitive data.

We can then rephrase the problem of quantifying this type of side channel vulnerability as calculating $\textrm{SAVAT}(s_a,s_b)$ for a given victim program and inputs without directly measuring $s_a(t)$ and $s_b(t)$. With some simplifying assumptions it is possible to calculate $\textrm{SAVAT}(s_a,s_b)$ by adding up all the single instruction differences between $s_a(t)$ and $s_b(t)$. For example, if $s_a(t)$ and $s_b(t)$ are the same except that the processor executes instruction B at some time $t_e$ during $s_b(t)$, while the processor executes instruction A at $t_e$ during $s_a(t)$, then $\textrm{SAVAT}(s_a,s_b) = \textrm{SAVAT}(A,B)$. Section~\ref{sec:methodology} presents a methodology for measuring $\textrm{SAVAT}(A,B)$ reliably using inexpensive equipment, and Appendix~\ref{appendix} presents a derivation showing that this methodology does measure $\textrm{SAVAT}(A,B)$ given a set of realistic assumptions. 

SAVAT quantifies the overall signal that is made available to the attacker through the side channel as a result of a single-instruction variation: executing a different instruction because of a control-flow decision, having or not having a cache miss, etc. The SAVAT is a pairwise metric: it measures the signal made available to the attacker when we execute instruction/event A instead of executing instruction/event B (or vice versa). For example, the ADD/MUL SAVAT is the overall side channel signal available to the attacker to determine whether we have executed an ADD or a MUL instruction, the LDM/LDL2 SAVAT is the overall amount of the side channel signal that tells the attacker whether we had a L2 hit or an off-chip memory access for a load instruction, etc. We also define the single-instruction SAVAT as the maximum of the pairwise SAVATs where both events in the pair are generated using the same instruction. For example, the SAVAT for a load instruction is the maximum of pairwise SAVATs: LDM/LDM, LDM/LDL2, LDM/LDL1, etc.

How many single-instruction differences need to be accumulated to mount a successful attack depends on the SAVAT values between these instructions -- huge SAVAT values enable attacks even when sensitive data creates a seemingly small difference in execution, e.g. the attacker may need fewer such ``loud'' instructions. Single instruction differences in execution may be accumulated in two ways: (1) repetition: the same single-instruction difference may be re-created many times, and the attacker can use the overall difference that is created, and (2) combination: entire sequences of different instructions can be executed. Our measurement methodology will exploit repetition to obtain signals that can be more reliably measured, then divides the large measured signal by the number of repetitions to determine the contribution of a single instance. Combination is not directly addressed in this work -- while we believe that the sum of single-instruction differences can act as a good estimate for the combined signal, this estimate is imprecise because instructions can be reordered and their execution may overlap. A more accurate SAVAT measurement of signal differences created by executing different sequences of instructions can be performed by using those entire sequences as A/B activity in the measurement. However, this approach does not scale well to longer sequences: pairwise SAVAT measurement for $N$ individual instructions requires $O(N^2)$ measurements, pairwise measurement among all possible two-instruction sequences constructed from these $N$ instructions requires $O(N^4)$ measurements, etc. One approach to this combinatorial explosion is to cluster instruction opcodes using SAVAT as the distance metric, then explore sequences using instruction class representatives. Another approach would be to derive a good model of the interaction among instructions in a sequence, i.e. to capture effects of reordering, dependencies, etc., and then compute overall SAVAT values for instruction sequences by using the interaction model to combine measured single-instruction SAVAT values. 
